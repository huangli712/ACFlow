#
# Project : Gardenia
# Source  : maxent.jl
# Author  : Li Huang (huangli@caep.cn)
# Status  : Unstable
#
# Last modified: 2023/04/18
#

#=
### *Customized Structs* : *MaxEnt Solver*
=#

"""
    MaxEntContext

Mutable struct. It is used within the MaxEnt solver only.

### Members

* G·µ•     -> Input data for correlator.
* œÉ¬≤     -> Actually 1.0 / œÉ¬≤.
* grid   -> Grid for input data.
* mesh   -> Mesh for output spectrum.
* model  -> Default model function.
* kernel -> Default kernel function.
* V‚Çõ     -> Matrix from singular value decomposition.
* W‚ÇÇ     -> Precomputed array.
* W‚ÇÉ     -> Precomputed array.
* B‚Çò     -> Precomputed array.
"""
mutable struct MaxEntContext
    G·µ•     :: Vector{F64}
    œÉ¬≤     :: Vector{F64}
    grid   :: AbstractGrid
    mesh   :: AbstractMesh
    model  :: Vector{F64}
    kernel :: Array{F64,2}
    hess   :: Array{F64,2}
    V‚Çõ     :: Array{F64,2}
    W‚ÇÇ     :: Array{F64,2}
    W‚ÇÉ     :: Array{F64,3}
    B‚Çò     :: Vector{F64}
end

#=
### *Global Drivers*
=#

"""
    solve(S::MaxEntSolver, rd::RawData)

Solve the analytical continuation problem by the maximum entropy method.
"""
function solve(S::MaxEntSolver, rd::RawData)
    println("[ MaxEnt ]")
    mec = init(S, rd)
    darr, sol = run(mec)
    gout = last(mec, darr, sol)
    return mec.mesh.mesh, sol[:A], gout
end

"""
    init(S::MaxEntSolver, rd::RawData)

Initialize the MaxEnt solver and return a MaxEntContext struct.
"""
function init(S::MaxEntSolver, rd::RawData)
    G = make_data(rd)
    G·µ• = G.value
    œÉ¬≤ = 1.0 ./ G.covar
    println("Postprocess input data: ", length(œÉ¬≤), " points")

    grid = make_grid(rd)
    println("Build grid for input data: ", length(grid), " points")

    mesh = make_mesh()
    println("Build mesh for spectrum: ", length(mesh), " points")

    model = make_model(mesh)
    println("Build default model: ", get_b("mtype"))

    kernel = make_kernel(mesh, grid)
    println("Build default kernel: ", get_b("ktype"))

    V‚Çõ, W‚ÇÇ, W‚ÇÉ, B‚Çò, hess = precompute(G·µ•, œÉ¬≤, mesh, model, kernel)
    println("Precompute key coefficients")

    return MaxEntContext(G·µ•, œÉ¬≤, grid, mesh, model,
                         kernel, hess, V‚Çõ, W‚ÇÇ, W‚ÇÉ, B‚Çò)
end

"""
    run(mec::MaxEntContext)

Perform maximum entropy simulation with different algorithms. Now it
supports the `historic`, `classic`, `bryan`, and `chi2kink` algorithms.
"""
function run(mec::MaxEntContext)
    stype = get_m("stype")
    method = get_m("method")

    # Note that the Bayesian Reconstruction entropy is compatible with
    # all the four algorithms so far.
    if stype == "br"
        prompt("Bayesian Reconstruction entropy is used!")
    else
        prompt("Shannon‚ÄìJaynes entropy is used!")
    end

    @cswitch method begin
        @case "historic"
            return historic(mec)
            break

        @case "classic"
            return classic(mec)
            break

        @case "bryan"
            return bryan(mec)
            break

        @case "chi2kink"
            return chi2kink(mec)
            break
    end
end

"""
    last(mec::MaxEntContext, svec::Vector, sol::Dict)

Postprocess the results generated during the maximum entropy simulations.
Here `sol` is the final solution for the analytical continuation problem,
while `svec` contains all the intermediate results (it is a vector of
dictionary actually).
"""
function last(mec::MaxEntContext, svec::Vector, sol::Dict)
    # Write the spectral function
    write_spectrum(mec.mesh, sol[:A])

    # Write the model function
    write_model(mec.mesh, mec.model)

    # Write Œ±-œá¬≤ data
    Œ±_vec = map(x -> x[:Œ±], svec)
    œá_vec = map(x -> x[:œá¬≤], svec)
    write_misfit(Œ±_vec, œá_vec)

    # Write P[Œ±|A] for bryan algorithm
    if haskey(svec[end], :prob)
        p_vec = map(x -> x[:prob], svec)
        write_probability(Œ±_vec, p_vec)
    end

    # Regenerate the input data and write them
    Aout = haskey(sol, :Araw) ? sol[:Araw] : sol[:A]
    G = reprod(mec.mesh, mec.kernel, Aout)
    write_backward(mec.grid, G)

    # Calculate full response function on real axis and write them
    if get_b("ktype") == "fermi"
        _G = kramers(mec.mesh, Aout)
    else
        _G = kramers(mec.mesh, Aout .* mec.mesh)
    end
    write_complete(mec.mesh, _G)

    return _G
end

#=
### *Core Algorithms*
=#

"""
    historic(mec::MaxEntContext)

Apply the historic algorithm to solve the analytical continuation problem.
It choose Œ± in a way that œá¬≤ ‚âà N.

For the historic algorithm, `alpha` is usually 10‚Å∂, and `ratio` is 10.0.
It is compatible with the Bayesian Reconstruction entropy.

See also: [`MaxEntContext`](@ref).
"""
function historic(mec::MaxEntContext)
    function root_fun(_Œ±, _u)
        res = optimizer(mec, _Œ±, _u, use_bayes)
        @. _u = res[:u]
        return length(mec.œÉ¬≤) / res[:œá¬≤] - 1.0
    end

    println("Apply historic algorithm to determine optimized Œ±")

    use_bayes = false
    alpha = get_m("alpha")
    ratio = get_m("ratio")
    n_svd = length(mec.B‚Çò)

    u_vec = zeros(F64, n_svd)
    s_vec = []

    conv = 0.0
    while conv < 1.0
        sol = optimizer(mec, alpha, u_vec, use_bayes)
        push!(s_vec, sol)
        alpha = alpha / ratio
        conv = length(mec.œÉ¬≤) / sol[:œá¬≤]
    end

    u_vec = s_vec[end-1][:u]
    alpha = s_vec[end][:Œ±]
    Œ±_opt = secant(root_fun, alpha, u_vec)

    sol = optimizer(mec, Œ±_opt, u_vec, use_bayes)
    println("Optimized Œ± : $Œ±_opt log10(Œ±) : $(log10(Œ±_opt))")

    return s_vec, sol
end

"""
    classic(mec::MaxEntContext)

Apply the classic algorithm to solve the analytical continuation problem.

Classic algorithm uses Bayes statistics to approximately determine the
most probable value of Œ±. We always start at a large value of Œ±, where
the optimization yields basically the default model, therefore `u_vec`
is only a few steps away from 0 (= default model). And then we gradually
decrease Œ±, step by step moving away from the default model towards data
fitting. Using `u_vec` as start for the next (smaller) Œ± brings a great
speedup into this procedure.

For the classic algorithm, `alpha` is usually 10‚Å∂, and `ratio` is 10.0.
It is incompatible with the Bayesian Reconstruction entropy.

See also: [`MaxEntContext`](@ref).
"""
function classic(mec::MaxEntContext)
    function root_fun(_Œ±, _u)
        res = optimizer(mec, _Œ±, _u, use_bayes)
        @. _u = res[:u]
        return res[:conv] - 1.0
    end

    println("Apply classic algorithm to determine optimized Œ±")

    use_bayes = true
    alpha = get_m("alpha")
    ratio = get_m("ratio")
    n_svd = length(mec.B‚Çò)

    u_vec = zeros(F64, n_svd)
    s_vec = []

    conv = 0.0
    while conv < 1.0
        sol = optimizer(mec, alpha, u_vec, use_bayes)
        push!(s_vec, sol)
        alpha = alpha / ratio
        @. u_vec = sol[:u]
        conv = sol[:conv]
    end

    c_vec = [x[:conv] for x in s_vec]
    Œ±_vec = [x[:Œ±] for x in s_vec]
    exp_opt = log10(Œ±_vec[end] / Œ±_vec[end-1])
    exp_opt = exp_opt / log10(c_vec[end] / c_vec[end-1])
    exp_opt = log10(Œ±_vec[end-1]) - log10(c_vec[end-1]) * exp_opt

    # Starting from the predicted value of Œ±, and starting optimization
    # at the solution for the next-lowest Œ±, we find the optimal Œ± by
    # secant root finding method.
    u_vec = s_vec[end-1][:u]
    alpha = 10.0 ^ exp_opt
    Œ±_opt = secant(root_fun, alpha, u_vec)

    sol = optimizer(mec, Œ±_opt, u_vec, use_bayes)
    println("Optimized Œ± : $Œ±_opt log10(Œ±) : $(log10(Œ±_opt))")

    return s_vec, sol
end

"""
    bryan(mec::MaxEntContext)

Apply the bryan algorithm to solve the analytical continuation problem.

Bryan's maxent calculates an average of spectral functions, weighted by
their Bayesian probability.

For the bryan algorithm, `alpha` is usually 500, and `ratio` is 1.1.
It is incompatible with the Bayesian Reconstruction entropy.

See also: [`MaxEntContext`](@ref).
"""
function bryan(mec::MaxEntContext)
    println("Apply bryan algorithm to determine optimized Œ±")

    use_bayes = true
    alpha = get_m("alpha")
    ratio = get_m("ratio")
    n_svd = length(mec.B‚Çò)
    nmesh = length(mec.mesh)

    u_vec = zeros(F64, n_svd)
    s_vec = []

    maxprob = 0.0
    while true
        sol = optimizer(mec, alpha, u_vec, use_bayes)
        push!(s_vec, sol)
        alpha = alpha / ratio
        @. u_vec = sol[:u]
        prob = sol[:prob]
        if prob > maxprob
            maxprob = prob
        elseif prob < 0.01 * maxprob
            break
        end
    end

    Œ±_vec = map(x->x[:Œ±], s_vec)
    p_vec = map(x->x[:prob], s_vec)
    p_vec = -p_vec ./ trapz(Œ±_vec, p_vec)
    A_vec = map(x->x[:A], s_vec)

    nprob = length(p_vec)
    A_opt = zeros(F64, nmesh)
    spectra = zeros(F64, nmesh, nprob)
    for i = 1:nprob
        spectra[:,i] = A_vec[i] * p_vec[i]
    end
    for j = 1:nmesh
        A_opt[j] = -trapz(Œ±_vec, spectra[j,:])
    end

    sol = Dict(:A => A_opt)

    return s_vec, sol
end

"""
    chi2kink(mec::MaxEntContext)

Apply the chi2kink algorithm to solve the analytical continuation problem.

We start with an optimization at a large value of Œ±, where we should get
only the default model. And then, Œ± is decreased step-by-step, until the
minimal value of Œ± is reached. Then, we fit a function

`œï(x; a, b, c, d) = a + b / [1 + exp(-d*(x-c))]`,

from which the optimal Œ± is determined by

`x_opt = c - fit_position / d`,

and

`alpha_opt = 10^x_opt`.

For the chi2kink algorithm, `alpha` is usually 10‚Åπ, `ratio` is 10.0, the
number of alpha parameters is 12. It is compatible with the Bayesian
Reconstruction entropy.

See also: [`MaxEntContext`](@ref).
"""
function chi2kink(mec::MaxEntContext)
    function fitfun(x, p)
        return @. p[1] + p[2] / (1.0 + exp(-p[4] * (x - p[3])))
    end

    println("Apply chi2kink algorithm to determine optimized Œ±")

    use_bayes = false
    alpha = get_m("alpha")
    ratio = get_m("ratio")
    nalph = get_m("nalph")
    Œ±_end = alpha / (ratio^nalph)
    n_svd = length(mec.B‚Çò)

    u_vec = zeros(F64, n_svd)
    s_vec = []
    œá_vec = []
    Œ±_vec = []

    while true
        sol = optimizer(mec, alpha, u_vec, use_bayes)
        push!(s_vec, sol)
        push!(Œ±_vec, alpha)
        push!(œá_vec, sol[:œá¬≤])
        @. u_vec = sol[:u]
        alpha = alpha / ratio
        if alpha < Œ±_end
            break
        end
    end

    good = isfinite.(œá_vec)
    guess = [0.0, 5.0, 2.0, 0.0]
    fit = curve_fit(fitfun, log10.(Œ±_vec[good]), log10.(œá_vec[good]), guess)
    _, _, c, d = fit.param

    # `fit_pos` is a control parameter for under/overfitting.
    # Good values are usually between 2 and 2.5. Smaller values usually
    # lead to underfitting, which is sometimes desirable. Larger values
    # lead to overfitting, which should be avoided.
    fit_pos = 2.5
    Œ±_opt = c - fit_pos / d
    close = argmin( abs.( log10.(Œ±_vec) .- Œ±_opt ) )
    u_vec = s_vec[close][:u]
    Œ±_opt = 10.0 ^ Œ±_opt

    sol = optimizer(mec, Œ±_opt, u_vec, use_bayes)
    println("Optimized Œ± : $Œ±_opt log10(Œ±) : $(log10(Œ±_opt))")

    return s_vec, sol
end

"""
    optimizer(mec::MaxEntContext, Œ±::F64, us::Vector{F64}, use_bayes::Bool)

Optimization of maxent functional for a given value of `Œ±`. Since a priori
the best value of `Œ±` is unknown, this function has to be called several
times in order to find a good value.

`Œ±` means a weight factor of the entropy. `us` is a vector in singular
space. It is used as a starting value for the optimization. For the very
first optimization, done at large Œ±, we use zeros, which corresponds to
the default model. Then we use the result of the previous optimization
as a starting value. `use_bayes` determines whether to use the Bayesian
inference parameters for `Œ±`.

This function will return a dictionary object that holds the results of
the optimization, e.g. spectral function, œá¬≤ deviation.
"""
function optimizer(mec::MaxEntContext, Œ±::F64, us::Vector{F64}, use_bayes::Bool)
    blur = get_m("blur")
    offdiag = get_b("offdiag")

    if offdiag
        solution, call = newton(f_and_J_offdiag, us, mec, Œ±)
        u = copy(solution)
        A = svd_to_real_offdiag(mec, solution)
        S = calc_entropy_offdiag(mec, A)
    else
        solution, call = newton(f_and_J, us, mec, Œ±)
        u = copy(solution)
        A = svd_to_real(mec, solution)
        S = calc_entropy(mec, A, u)
    end

    œá¬≤ = calc_chi2(mec, A)
    norm = trapz(mec.mesh, A)

    dict = Dict{Symbol,Any}(
        :u => u,
        :Œ± => Œ±,
        :S => S,
        :œá¬≤ => œá¬≤,
        :norm => norm,
        :Q => Œ± * S - 0.5 * œá¬≤,
        :Araw => deepcopy(A),
    )

    if use_bayes
        if offdiag
            ng, tr, conv, prob = calc_bayes_offdiag(mec, A, S, œá¬≤, Œ±)
        else
            ng, tr, conv, prob = calc_bayes(mec, A, S, œá¬≤, Œ±)
        end
        dict[:ngood] = ng
        dict[:trace] = tr
        dict[:conv] = conv
        dict[:prob] = prob
    end

    if blur > 0.0
        make_blur(mec.mesh, A, blur)
    end
    dict[:A] = A

    @printf("log10(Œ±) = %8.4f ", log10(Œ±))
    @printf("œá¬≤ = %8.4e ", œá¬≤)
    @printf("S = %8.4e ", S)
    @printf("call = %4i ", call)
    @printf("norm = %8.4f\n", norm)

    return dict
end

#=
### *Service Functions*
=#

#=
*Remarks* :

Try to calculate some key variables by using the Einstein summation trick.

```math
\begin{equation}
B_m = \sum^{N}_{n = 1} \frac{1}{\sigma^2_n} \xi_m U_{nm} G_n,
\end{equation}
```

```math
\begin{equation}
W_{ml} = \sum_{pn} \frac{1}{\sigma^2_n}
    U_{nm}\xi_m U_{np} \xi_p V_{lp} \Delta_l D_l,
\end{equation}
```

```math
\begin{equation}
W_{mli} = W_{ml} V_{li}.
\end{equation}
```

Note that these variables do not depend on the spectral function
``A(\omega)``, so they could be computed at advance to improve the
computational efficiency.

---

The `hessian matrix` is also calculated here.

```math
\begin{equation}
L = \frac{1}{2} \chi^2,
\end{equation}
```

```math
\begin{equation}
\frac{\partial^2 L}{\partial A_i \partial A_j} =
\sum_n \frac{K_{ni} \Delta_i K_{nj} \Delta_j}{\sigma^2_n}.
\end{equation}
```
=#

"""
    precompute(G·µ•::Vector{F64}, œÉ¬≤::Vector{F64},
               am::AbstractMesh,
               D::Vector{F64},
               K::Matrix{F64})

Precompute some key coefficients. Here `G·µ•` and `œÉ¬≤` are input data, `am`
is the mesh for spectrum, `D` is the default model, and `K` is the kernel
function.
"""
function precompute(G·µ•::Vector{F64}, œÉ¬≤::Vector{F64},
                    am::AbstractMesh,
                    D::Vector{F64},
                    K::Matrix{F64})
    # Create singular value space
    U, V, S = make_singular_space(K)

    # Evaluate sizes of the arrays
    nmesh = length(am)
    n_svd = length(S)

    # Allocate memories
    W‚ÇÇ = zeros(F64, n_svd, nmesh)
    W‚ÇÉ = zeros(F64, n_svd, n_svd, nmesh)
    B‚Çò = zeros(F64, n_svd)
    hess = zeros(F64, nmesh, nmesh)

    # Get weight of the mesh, Œîœâ‚Çó.
    Œî = am.weight

    # Compute W‚Çò‚Çó
    @einsum W‚ÇÇ[m,l] = œÉ¬≤[k] * U[k,m] * S[m] * U[k,n] * S[n] * V[l,n] * Œî[l] * D[l]

    # Compute W‚Çò‚Çó·µ¢
    @einsum W‚ÇÉ[m,k,l] = W‚ÇÇ[m,l] * V[l,k]

    # Compute B‚Çò
    @einsum B‚Çò[m] = S[m] * U[k,m] * œÉ¬≤[k] * G·µ•[k]

    # Compute the Hessian matrix
    @einsum hess[i,j] = Œî[i] * Œî[j] * K[k,i] * K[k,j] * œÉ¬≤[k]

    return V, W‚ÇÇ, W‚ÇÉ, B‚Çò, hess
end

#=
*Remarks* :

For Shannon-Jaynes entropy,

```math
\begin{equation}
w_l = \exp \left(\sum_m V_{lm} u_m\right).
\end{equation}
```

```math
\begin{equation}
f_m = \alpha u_m + \sum_l W_{ml} w_l - B_m.
\end{equation}
```

```math
\begin{equation}
J_{mi} = \alpha \delta_{mi} + \sum_l W_{mli} w_l.
\end{equation}
```

---

For Bayesian Reconstruction entropy,

```math
\begin{equation}
w_l = \frac{1}{1 - D_l \sum_m V_{lm} u_m}.
\end{equation}
```

```math
\begin{equation}
f_m = \alpha u_m + \sum_l W_{ml} w_l - B_m.
\end{equation}
```

```math
\begin{equation}
J_{mi} = \alpha \delta_{mi} + \sum_l W_{mli} D_l w_l w_l.
\end{equation}
```
=#

"""
    f_and_J(u::Vector{F64}, mec::MaxEntContext, Œ±::F64)

This function evaluates the function whose root we want to find. Here
`u` is a singular space vector that parametrizes the spectral function,
and `Œ±` is a (positive) weight factor of the entropy.

It returns `f`, value of the function whose zero we want to find, and
`J`, jacobian at the current position.

See also: [`f_and_J_offdiag`](@ref).
"""
function f_and_J(u::Vector{F64}, mec::MaxEntContext, Œ±::F64)
    stype = get_m("stype")

    n_svd = length(mec.B‚Çò)
    J = diagm([Œ± for i = 1:n_svd])

    if stype == "sj"
        w = exp.(mec.V‚Çõ * u)
        #
        for j = 1:n_svd
            for i = 1:n_svd
                J[i,j] = J[i,j] + dot(mec.W‚ÇÉ[i,j,:], w)
            end
        end
        #
        f = Œ± * u + mec.W‚ÇÇ * w - mec.B‚Çò
    else
        w = mec.V‚Çõ * u
        w‚ÇÅ = 1.0 ./ (1.0 .- mec.model .* w)
        w‚ÇÇ = w‚ÇÅ .* w‚ÇÅ .* mec.model
        #
        for j = 1:n_svd
            for i = 1:n_svd
                J[i,j] = J[i,j] + dot(mec.W‚ÇÉ[i,j,:], w‚ÇÇ)
            end
        end
        #
        f = Œ± * u + mec.W‚ÇÇ * w‚ÇÅ - mec.B‚Çò
    end

    return f, J
end

#=
*Remarks* :

For Shannon-Jaynes entropy,

```math
\begin{equation}
w_l = \exp \left(\sum_m V_{lm} u_m\right).
\end{equation}
```

```math
\begin{equation}
f_m = \alpha u_m +
      \sum_l W_{ml}\left(w_l - \frac{1}{w_l}\right) - B_m.
\end{equation}
```

```math
\begin{equation}
J_{mi} = \alpha \delta_{mi} +
         \sum_{l} W_{mli} \left(w_l + \frac{1}{w_l}\right).
\end{equation}
```

---

For Bayesian Reconstruction entropy,

```math
\begin{equation}
w^+_l = \frac{1}{ 1 - D_l \sum_m V_{lm} u_m}.
\end{equation}
```

```math
\begin{equation}
w^-_l = \frac{1}{ 1 + D_l \sum_m V_{lm} u_m}.
\end{equation}
```

```math
\begin{equation}
f_m = \alpha u_m + \sum_l W_{ml} (w^+_l - w^-_l) - B_m.
\end{equation}
```

```math
\begin{equation}
J_{mi} = \alpha \delta_{mi} + \sum_l W_{mli} D_l (w^+_l w^+_l + w^-_l w^-_l).
\end{equation}
```
=#

"""
    f_and_J_offdiag(u::Vector{F64}, mec::MaxEntContext, Œ±::F64)

This function evaluates the function whose root we want to find. Here
`u` is a singular space vector that parametrizes the spectral function,
and `Œ±` is a (positive) weight factor of the entropy.

It returns `f`, value of the function whose zero we want to find, and
`J`, jacobian at the current position.

This function is similar to `f_and_J`, but for offdiagonal elements.

See also: [`f_and_J`](@ref).
"""
function f_and_J_offdiag(u::Vector{F64}, mec::MaxEntContext, Œ±::F64)
    stype = get_m("stype")

    n_svd = length(mec.B‚Çò)
    J = diagm([Œ± for i = 1:n_svd])

    if stype == "sj"
        w = exp.(mec.V‚Çõ * u)
        #
        a‚Å∫ = 1.0 .* w
        a‚Åª = 1.0 ./ w
        a‚ÇÅ = a‚Å∫ - a‚Åª
        a‚ÇÇ = a‚Å∫ + a‚Åª
        #
        for j = 1:n_svd
            for i = 1:n_svd
                J[i,j] = J[i,j] + dot(mec.W‚ÇÉ[i,j,:], a‚ÇÇ)
            end
        end
        #
        f = Œ± * u + mec.W‚ÇÇ * a‚ÇÅ - mec.B‚Çò
    else
        w = mec.V‚Çõ * u
        #
        a‚Å∫ = 1.0 ./ (1.0 .- mec.model .* w)
        a‚Åª = 1.0 ./ (1.0 .+ mec.model .* w)
        a‚ÇÅ = a‚Å∫ - a‚Åª
        a‚ÇÇ = (a‚Å∫ .* a‚Å∫ + a‚Åª .* a‚Åª) .* mec.model
        #
        for j = 1:n_svd
            for i = 1:n_svd
                J[i,j] = J[i,j] + dot(mec.W‚ÇÉ[i,j,:], a‚ÇÇ)
            end
        end
        #
        f = Œ± * u + mec.W‚ÇÇ * a‚ÇÅ - mec.B‚Çò        
    end

    return f, J
end

#=
*Remarks* :

For Shannon-Jaynes entropy,

```math
\begin{equation}
A_l = D_l \exp \left(\sum_m V_{lm} u_m\right).
\end{equation}
```

---

For Bayesian Reconstruction entropy,

```math
\begin{equation}
A_l = \frac{D_l}{ 1 - D_l \sum_m V_{lm} u_m}.
\end{equation}
```
=#

"""
    svd_to_real(mec::MaxEntContext, u::Vector{F64})

Go from singular value space to real space. It will transform the singular
space vector `u` into real-frequency space (to get the spectral function)
by `A(œâ) = D(œâ) e‚±Ω·µò`, where `D(œâ)` is the default model `V` is the matrix
from the singular value decomposition. The argument `u` means a singular
space vector that parametrizes the spectral function.

See also: [`svd_to_real_offdiag`](@ref).
"""
function svd_to_real(mec::MaxEntContext, u::Vector{F64})
    stype = get_m("stype")
    #
    if stype == "sj"
        w = exp.(mec.V‚Çõ * u)
        return mec.model .* w
    else
        w = mec.V‚Çõ * u
        return mec.model ./ (1.0 .- mec.model .* w)
    end
end

#=
*Remarks* :

For Shannon-Jaynes entropy,

```math
\begin{equation}
A_l = D_l \exp \left(\sum_m V_{lm} u_m\right) -
      D_l \exp \left(-\sum_m V_{lm} u_m\right).
\end{equation}
```

---

For Bayesian Reconstruction entropy,

```math
\begin{equation}
w^+_l = \frac{1}{ 1 - D_l \sum_m V_{lm} u_m}.
\end{equation}
```

```math
\begin{equation}
w^-_l = \frac{1}{ 1 + D_l \sum_m V_{lm} u_m}.
\end{equation}
```

```math
\begin{equation}
A_l = D_l (w^+_l - w^-_l).
\end{equation}
```
=#

"""
    svd_to_real_offdiag(mec::MaxEntContext, u::Vector{F64})

Go from singular value space to real space. It will transform the singular
space vector `u` into real-frequency space in the case of an offdiagonal
element. It will return the spectral function.

See also: [`svd_to_real`](@ref).
"""
function svd_to_real_offdiag(mec::MaxEntContext, u::Vector{F64})
    stype = get_m("stype")
    #
    if stype == "sj"
        w = exp.(mec.V‚Çõ * u)
        w‚Å∫ = w
        w‚Åª = 1.0 ./ w
        return mec.model .* (w‚Å∫ .- w‚Åª)
    else
        w = mec.V‚Çõ * u
        w‚Å∫ = 1.0 ./ (1.0 .- mec.model .* w)
        w‚Åª = 1.0 ./ (1.0 .+ mec.model .* w)
        return mec.model .* (w‚Å∫ .- w‚Åª)
    end
end

#=
*Remarks* :

Shannon‚ÄìJaynes entropy

```math
\begin{equation}
S[A] = \int^{\infty}_0 d\omega
\left[
    A - m -
    A \log{\left(\frac{A}{m}\right)}
\right],
\end{equation}
```

```math
\begin{equation}
S[A^{+},A^{-}] = \int^{+\infty}_0 d\omega
\left[
    \sqrt{A^2 + 4m^2} - 2m -
    A\log{\left(\frac{\sqrt{A^2 + 4m^2} + A}{2m}\right)}
\right].
\end{equation}
```

---

Bayesian Reconstruction entropy

```math
\begin{equation}
S[A] = \int^{\infty}_0 d\omega
\left[
    1 - \frac{A}{m} + \log{\left(\frac{A}{m}\right)}
\right],
\end{equation}
```

```math
\begin{equation}
S[A^{+},A^{-}] = \int^{+\infty}_0 d\omega
\left[
    2 - \frac{\sqrt{A^2 + m^2} + m}{m} +
    \log{\left(\frac{\sqrt{A^2 + m^2} + m}{2m}\right)}
\right].
\end{equation}
```
=#

"""
    calc_entropy(mec::MaxEntContext, A::Vector{F64}, u::Vector{F64})

It computes entropy for positive definite spectral function. Here the
arguments `A` means spectral function and `u` means a singular space
vector that parametrizes the spectral function.

See also: [`calc_entropy_offdiag`](@ref).
"""
function calc_entropy(mec::MaxEntContext, A::Vector{F64}, u::Vector{F64})
    stype = get_m("stype")
    #
    if stype == "sj"
        f = A - mec.model - A .* (mec.V‚Çõ * u)
    else
        ùëÖ = A ./ mec.model
        if any(x -> x < 0.0, ùëÖ)
            prompt("Negative spectrum occurs!")
            f = 1.0 .- ùëÖ + log.(abs.(ùëÖ))
        else
            f = 1.0 .- ùëÖ + log.(ùëÖ)
        end
    end
    #
    return trapz(mec.mesh, f)
end

"""
    calc_entropy_offdiag(mec::MaxEntContext, A::Vector{F64})

It compute *positive-negative entropy* for spectral function with norm 0.
Here the argument `A` means spectral function.

See also: [`calc_entropy`](@ref).
"""
function calc_entropy_offdiag(mec::MaxEntContext, A::Vector{F64})
    stype = get_m("stype")
    #
    if stype == "sj"
        root = sqrt.(A .^ 2.0 + 4.0 .* mec.model .* mec.model)
        f = root - 2.0 .* mec.model
        f = f - A .* log.((root + A) ./ (2.0 .* mec.model))
    else
        root = sqrt.(A .^ 2.0 + mec.model .^ 2.0) + mec.model
        f = 2.0 .- (root ./ mec.model) + log.(root ./ (2.0 .* mec.model))
    end
    #
    return trapz(mec.mesh, f)
end

#=
*Remarks* :

**Posterior distribution of ``\alpha``**

Because
```math
\begin{equation}
\text{Pr}[\alpha | \bar{G}] =
\text{Pr}[\alpha] \frac{e^Q}{Z_L Z_S}
\frac{(2\pi)^{N/2}}{\sqrt{\det{[\alpha I + \Lambda]}}},
\end{equation}
```

so
```math
\begin{equation}
\log \text{Pr}[\alpha | \bar{G}] =
\text{constant} + \log \text{Pr} [\alpha] +
\frac{1}{2} \text{Tr} \log \left[\frac{\alpha I}{\alpha I + A}\right] +
\alpha S - \frac{1}{2}\chi^2.
\end{equation}
```

The defining equation for the `classic MaxEnt` equation reads:

```math
-2\alpha S = \text{Tr} \left(\frac{\Lambda}{\alpha I + \Lambda}\right).
```

The summation on the right hand side of the above equation is defined to
be ``N_g``, the number of good measurements:

```math
\begin{equation}
N_g = \text{Tr} \left(\frac{\Lambda}{\alpha I + \Lambda}\right).
\end{equation}
```

If ``\lambda_i`` are the eigenvalues of ``\Lambda``, then

```math
\begin{equation}
N_g = \sum_i \frac{\lambda_i}{\alpha + \lambda_i}.
\end{equation}
```

**``\Lambda`` matrix**

For Shannon-Jaynes entropy,

```math
\begin{equation}
\frac{\partial^2 S[A]}{\partial A_i \partial A_j} =
-\delta_{ij}\frac{\Delta_i}{A_i} =
-\delta_{ij}\frac{\sqrt{\Delta_i \Delta_j}}{\sqrt{A_i A_j}},
\end{equation}
```

```math
\begin{equation}
\Lambda_{ij} = \sqrt{\frac{A_i}{\Delta_i}}
               \frac{\partial^2 L}{\partial A_i \partial A_j}
               \sqrt{\frac{A_j}{\Delta_j}}.
\end{equation}
```

```math
\begin{equation}
\frac{\partial^2 S[A^+,A^-]}{\partial A_i \partial A_j} =
-\delta_{ij}\frac{\Delta_i}{\sqrt{A_i^2 + 4m_i^2}} =
-\delta_{ij}\frac{\sqrt[4]{\Delta^2_i}\sqrt[4]{\Delta^2_j}}
                 {\sqrt[4]{A_i^2 + 4m_i^2} \sqrt[4]{A_j^2 + 4m_j^2}},
\end{equation}
```

```math
\begin{equation}
\Lambda_{ij} = \sqrt[4]{\frac{A^2_i + 4m_i^2}{\Delta^2_i}}
               \frac{\partial^2 L}{\partial A_i \partial A_j}
               \sqrt[4]{\frac{A^2_j + 4m_j^2}{\Delta^2_j}}.
\end{equation}
```

---

For Bayesian Reconstruction entropy,

```math
\begin{equation}
\frac{\partial^2 S[A]}{\partial A_i \partial A_j} =
-\delta_{ij} \frac{\Delta_i}{A^2_i} = 
-\delta_{ij} \frac{\sqrt{\Delta_i \Delta_j}}{A_i A_j},
\end{equation}
```

```math
\begin{equation}
\Lambda_{ij} = \frac{A_i}{\sqrt{\Delta_i}}
               \frac{\partial^2 L}{\partial A_i \partial A_j}
               \frac{A_j}{\sqrt{\Delta_j}}.
\end{equation}
```

**Reference:**

[1] G. J. Kraberger, *et al.*, Phys. Rev. B **96**, 155128 (2017).

[2] M. Jarrell, *et al.*, Phys. Rep. **269**, 133 (1996).
=#

"""
    calc_bayes(mec::MaxEntContext,
               A::Vector{F64},
               S::F64, œá¬≤::F64, Œ±::F64)

It calculates Bayesian convergence criterion (`ng`, `tr`, and `conv`) for
classic maxent (maximum of probablility distribution) and then Bayesian
a-posteriori probability (`log_prob`) for `Œ±` after optimization of `A`.

Here, `A` is the spectral function, `S` the entropy, `œá¬≤` the deviation,
and `Œ±` weight factor of the entropy.

See also: [`calc_bayes_offdiag`](@ref).
"""
function calc_bayes(mec::MaxEntContext,
                    A::Vector{F64},
                    S::F64, œá¬≤::F64, Œ±::F64)
    stype = get_m("stype")
    mesh = mec.mesh

    if stype == "sj"
        T = sqrt.(A ./ mesh.weight)
    else
        T = A ./ sqrt.(mesh.weight)
    end
    Œõ = (T * T') .* mec.hess

    Œª = eigvals(Hermitian(Œõ))
    ng = -2.0 * Œ± * S
    tr = sum(Œª ./ (Œ± .+ Œª))
    conv = tr / ng

    eig_sum = sum(log.(Œ± ./ (Œ± .+ Œª)))
    log_prob = Œ± * S - 0.5 * œá¬≤ + log(Œ±) + 0.5 * eig_sum

    return ng, tr, conv, exp(log_prob)
end

"""
    calc_bayes_offdiag(mec::MaxEntContext,
                       A::Vector{F64},
                       S::F64, œá¬≤::F64, Œ±::F64)

It calculates Bayesian convergence criterion (`ng`, `tr`, and `conv`) for
classic maxent (maximum of probablility distribution) and then Bayesian
a-posteriori probability (`log_prob`) for `Œ±` after optimization of `A`.

Here, `A` is the spectral function, `S` the entropy, `œá¬≤` the deviation,
and `Œ±` weight factor of the entropy.

It is just a offdiagonal version of `calc_bayes()`.

See also: [`calc_bayes`](@ref).
"""
function calc_bayes_offdiag(mec::MaxEntContext,
                            A::Vector{F64},
                            S::F64, œá¬≤::F64, Œ±::F64)
    mesh = mec.mesh

    T = (( A .^ 2.0 + 4.0 * mec.model .* mec.model ) / (mesh.weight .^ 2.0)) .^ 0.25
    Œõ = (T * T') .* mec.hess

    Œª = eigvals(Hermitian(Œõ))
    ng = -2.0 * Œ± * S
    tr = sum(Œª ./ (Œ± .+ Œª))
    conv = tr / ng

    eig_sum = sum(log.(Œ± ./ (Œ± .+ Œª)))
    log_prob = Œ± * S - 0.5 * œá¬≤ + log(Œ±) + 0.5 * eig_sum

    return ng, tr, conv, exp(log_prob)
end

"""
    calc_chi2(mec::MaxEntContext, A::Vector{F64})

It computes the œá¬≤-deviation of the spectral function `A`.
"""
function calc_chi2(mec::MaxEntContext, A::Vector{F64})
    G‚Çô = reprod(mec.mesh, mec.kernel, A)
    œá¬≤ = sum(mec.œÉ¬≤ .* ((mec.G·µ• - G‚Çô) .^ 2.0))
    return œá¬≤
end
